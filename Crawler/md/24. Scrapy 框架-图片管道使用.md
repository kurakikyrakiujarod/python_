

[下载项目图片](https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/images.html)

### 具体流程(此处以zol网站为例)

1. 定义item
```python
import scrapy


class ImagedownloadItem(scrapy.Item):
    # define the fields for your item here like:
    img_name = scrapy.Field()
    img_urls = scrapy.Field()
```

2. 编写spider
```python
# 获取文件地址-->获取图片名称-->推送地址
class ZolSpiderSpider(scrapy.Spider):
    name = 'zol'
    allowed_domains = ['zol.com.cn']
    url ='http://desk.zol.com.cn'
    start_urls = [url+'/bizhi/7106_88025_2.html']

    def parse(self, response):
        image_url = response.xpath('//img[@id="bigImg"]/@src').extract_first()
        image_name = response.xpath('//h3')[0].xpath('string(.)').extract_first().strip().replace('\r\n\t\t', '')
        next_image = response.xpath('//a[@id="pageNext"]/@href').extract_first()
        item = ImagedownloadItem()
        item["img_name"] = image_name
        item["img_urls"] = image_url
        
        yield item
        yield scrapy.Request(self.url+next_image,callback=self.parse)
```
3. 编写pipline

 以下如果不想改文件名，meta属性可以忽略不写

```python
    def get_media_requests(self, item, info):
        '''
        #如果item[urls]里里面是列表，用下面
        urls= item['urls']
        for url in urls:
            yield scrapy.Request(url,meta={"item",item})
        '''
        # 如果item[urls]里里面是一个图片地址，用这下面的
        yield scrapy.Request(item['img_urls'], meta={"item": item})
```

因为scrapy里是使用它们URL的 SHA1 hash 作为文件名，所以如果想重命名：
```python
  def file_path(self, request, response=None, info=None):
        item = request.meta["item"]
        #去掉文件里的/,避免创建图片文件时出错
        filename = item["img_name"].replace("/","-")+".jpg"

        return filename
```
4. 定义图片保存在哪？
在settings中增加一句
```python
IMAGES_STORE = "e:/pics"
```