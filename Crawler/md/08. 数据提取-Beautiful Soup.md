### 1. Beautiful Soup的简介

[官网](http://beautifulsoup.readthedocs.io/zh_CN/latest/)http://beautifulsoup.readthedocs.io/zh_CN/latest/
### 2. Beautiful Soup 安装
```
pip install beautifulsoup4
```

Beautiful Soup支持Python标准库中的HTML解析器，还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装。

解析器 | 使用方法 | 优势  | 劣势
--- | --- | --- | ---
Python标准库 | BeautifulSoup(markup, “html.parser”)| 1. Python的内置标准库  2. 执行速度适中 3.文档容错能力强 |Python 2.7.3 or 3.2.2)前 的版本中文档容错能力差
lxml HTML 解析器 | BeautifulSoup(markup, “lxml”)	| 1. 速度快 2.文档容错能力强  | 需要安装C语言库
lxml XML 解析器 | BeautifulSoup(markup, [“lxml”, “xml”])  BeautifulSoup(markup, “xml”) | 1. 速度快 2.唯一支持XML的解析器 |需要安装C语言库
html5lib | BeautifulSoup(markup, “html5lib”) | 1. 最好的容错性 2.以浏览器的方式解析文档 3.生成HTML5格式的文档 4.速度慢 | 不依赖外部扩展

### 3. 创建 Beautiful Soup 对象

```python
from bs4 import BeautifulSoup

bs = BeautifulSoup(html,"lxml")
```

### 4. 四大对象种类
Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象，所有对象可以归纳为4种:

- Tag
- NavigableString
- BeautifulSoup
- Comment

#### 4.1 Tag 

使用方式：

```html
#以以下代码为例子
<title>尚学堂</title>
<div class='info' float='left'>Welcome to SXT</div>
<div class='info' float='right'>
    <span>Good Good Study</span>
    <a href='www.bjsxt.cn'></a>
    <strong><!--没用--></strong>
</div>
```
##### 4.1.1 获取标签

```python
#以lxml方式解析
soup = BeautifulSoup(info, 'lxml')
#相同的标签只能获取第一个符合要求的标签
print(soup.title)
# <title>尚学堂</title>
```

##### 4.1.2 获取属性：
```python
#获取所有属性
print(soup.div.attrs)
#{'class': ['info'], 'float': 'left'}

#获取单个属性的值
print(soup.div.get('class'))
print(soup.div['class'])
print(soup.a['href'])
```

#### 4.2 NavigableString 获取内容

```python
print(soup.title.string)
print(soup.title.text)
#尚学堂
```

#### 4.3 BeautifulSoup
```python
print(soup.name)
print(soup.head.name)
# [document]
# head
```

#### 4.4 Comment
Comment 对象是一个特殊类型的 NavigableString 对象，其实输出的内容仍然不包括注释符号，但是如果不好好处理它，可能会对我们的文本处理造成意想不到的麻烦。

```python
from bs4.element import Comment
if type(soup.strong.string)==Comment:
    print(soup.strong.prettify())
    #print(soup.strong.string)
    #print(soup.strong.text)
else:
    print(soup.strong.string)
```

### 5 搜索文档树
#### 5.1 过滤器
##### 5.1.1 字符串
```python
#返回所有的div标签
print(soup.find_all('div'))
```
如果传入字节码参数，Beautiful Soup会当作UTF-8编码，可以传入一段Unicode 编码来避免Beautiful Sou解析编码出错。

##### 5.1.2 正则表达式
如果传入正则表达式作为参数，Beautiful Soup会通过正则表达式的 match() 来匹配内容。
```python
#返回所有的div标签
print(soup.find_all(re.compile("^div")))
```
##### 5.1.3 列表
如果传入列表参数，Beautiful Soup会将与列表中任一元素匹配的内容返回。

```python
#返回所有匹配到的span a标签
print(soup.find_all(['span','a']))
```
##### 5.1.4 keyword
如果一个指定名字的参数不是搜索内置的参数名，搜索时会把该参数当作指定名字tag的属性来搜索，如果包含一个名字为 id 的参数，Beautiful Soup会搜索每个tag的”id”属性。

```python
#返回id为welcom的标签
print(soup.find_all(id='welcom'))
```
##### 5.1.4 True
True 可以匹配任何值，下面代码查找到所有的tag，但是不会返回字符串节点。

##### 5.1.5 按CSS搜索
按照CSS类名搜索tag的功能非常实用，但标识CSS类名的关键字 class 在Python中是保留字，使用 class 做参数会导致语法错误。从Beautiful Soup的4.1.1版本开始，可以通过 class_ 参数搜索有指定CSS类名的tag

```python
# 返回class等于info的div
print(soup.find_all('div',class_='info'))
```
##### 5.1.6 按属性搜索

```python
soup.find_all("div", attrs={"class": "info"})
```
### 6. CSS选择器（扩展）
soup.select(参数)

表达式 | 说明
--|--
tag | 选择指定标签
*	| 选择所有节点
#id	|选择id为container的节点
.class	|选取所有class包含container的节点
li a	|选取所有li下的所有a节点
ul + p	|(兄弟)选择ul后面的第一个p元素
div#id > ul	|(父子)选取id为id的div的第一个ul子元素
table ~ div	|选取与table相邻的所有div元素
a[title]	|选取所有有title属性的a元素
a[class=”title”]	|选取所有class属性为title值的a
a[href*=”sxt”]	|选取所有href属性包含sxt的a元素
a[href^=”http”]	|选取所有href属性值以http开头的a元素
a[href$=”.png”]	|选取所有href属性值以.png结尾的a元素
input[type="redio"]:checked	|选取选中的hobby的元素